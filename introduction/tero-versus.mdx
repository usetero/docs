---
title: "How Tero compares"
sidebarTitle: "Tero versus"
description: "Where Tero fits in your stack"
icon: "code-compare"
iconType: "duotone"
---

Tero is a control plane. It sits above your existing tools and makes them better. It doesn't replace anything.

## Observability platforms

**Datadog, Splunk, New Relic, Grafana**

These are where your data lives. They store it, query it, visualize it. Tero connects via API and builds understanding on top.

Your platform knows the format of your data. Tero knows the meaning: which logs matter during incidents, which metrics are never queried, what's waste and what's valuable. That understanding becomes policies you can enforce.

Swap platforms, add new ones, run multiple. Tero works across all of them. The policies are portable.

## Pipelines

**Cribl, Vector, Fluent Bit, OTel Collector**

Pipelines move data. They're good at routing, buffering, and basic transforms. But when you use them for data quality at scale, the config model breaks down. Thousands of rules with ordering dependencies, no portability between tools, performance that degrades as complexity grows.

Tero takes a different approach. [Policies](/policies) are atomic and independent. Ten thousand execute as fast as ten. They're portable across any runtime. And we're bringing the policy engine to pipelines directly, starting with OTel Collector and Vector, so you can enforce policies wherever your data already flows.

Tero generates the policies from the [Master Catalog](/master-catalog). You review and approve. They execute in your pipeline, at the edge, or via your provider's API. The understanding lives in Tero. Enforcement lives wherever makes sense.

## Cost tools

**CloudZero, Vantage**

Cost tools show you what you're spending. Dashboards, reports, breakdowns by team or service.

Tero shows you what's wrong with your data and how to fix it. Costs drop as a consequence of cleaning up the waste. The goal isn't a better dashboard. It's better data.

## AI SREs

Copilots that help debug incidents, answer questions about your systems, and automate runbooks.

They're useful for what they do. But ask: what percentage of my data is waste? They can't tell you. That requires comprehensive understanding of all your telemetry. What exists, what it means, whether it's used. Answering questions about your data isn't the same as understanding all of it.

Tero has the [Master Catalog](/master-catalog). Every question is answered against complete knowledge, not partial views.
