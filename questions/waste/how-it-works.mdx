---
title: "How Tero evaluates waste"
sidebarTitle: "How it works"
description: "The method behind waste analysis"
icon: "gear"
iconType: "duotone"
---

Chances are you've done manual waste analysis. Maybe before a renewal, or your boss wanted your service's log cost down. Why were you chosen? Probably because you have the deepest understanding of the service.

Maybe you wrote the code, or added the instrumentation. Maybe you just operate the service. Either way, you know the core functions, where it sits in the graph, which services it talks to, critical failure modes, common failure modes. Context accumulated over time.

When you look at a log, you can say with some confidence whether it's waste. It's not binary; it's a gradient. Obvious waste requires little context. Nuanced waste requires understanding the service, the event, the situation where someone might need it.

But this process is slow. Intensive. Manual. It has an opportunity cost. It's a concern you carry around, a distraction from net-positive work. Maybe you do it quarterly, but you're limited to the obvious stuff. How much is left? And what's the compounding cost of the waste you didn't catch, paid month after month until the next review?

Tero takes this off your plate so you can focus on building product and being a great engineer.

## Logs

How do you analyze billions of logs without missing a single one?

We start by compressing raw logs into [semantic log events](/context/log-events). Each raw log maps to a single event. Billions of lines become thousands of events with rich meaning. Now evaluation is tractable.

Each event inherits context from your [service catalog](/context/services): what the service does, where it sits in your architecture, which services depend on it, known failure modes. This is the same context you carry in your head, but explicit and always current.

With this context, Tero evaluates each event the way you would. Starting with the obvious and progressing to the nuanced.

### Drop

We're conservative about dropping. These are logs that could never help an investigation.

<AccordionGroup>
  <Accordion title="Junk" icon="file-circle-xmark">
    Malformed data, binary blobs, accidental output. `fdsfdsfdseef`. Logs that convey nothing useful. Safe to eliminate entirely.
  </Accordion>
  <Accordion title="Debug output" icon="bug">
    Debug markers, developer notes, breadcrumbs that shouldn't be in production. `GOT HERE!`, `TODO: remove this`, print statements left behind. Safe to eliminate entirely.
  </Accordion>
  <Accordion title="External probes" icon="heart-pulse">
    Health checks, readiness probes, synthetic monitoring hitting your service from outside. Infrastructure talking to itself. Health check *failures* are different. Those have investigative value.
  </Accordion>
</AccordionGroup>

### Sample

If this event fires 1000 times in a second, is that 1000 problems worth investigating, or 1000 data points about the same problem? When it's the same situation repeated, sample to reduce volume without losing visibility.

<Note>
Tero only recommends correlated sampling. By trace ID, request ID, or similar. All logs from the same request stay together or drop together. We never turn your logs into swiss cheese.
</Note>

<AccordionGroup>
  <Accordion title="Noisy signals" icon="volume-high">
    High volume, low variance. Cache hits, heartbeats, routine operations. 1000 cache hits means the cache worksâ€”that's one situation, not 1000 investigations. Keep a sample for proof-of-life.
  </Accordion>
  <Accordion title="System errors during outages" icon="server">
    A database timeout during an outage? A thousand requests hitting that timeout are symptoms of one problem, not a thousand separate incidents. Sample to capture the pattern without the flood.
  </Accordion>
</AccordionGroup>

### Trim

The log matters. Some attributes don't. Keep the event, remove the noise.

<AccordionGroup>
  <Accordion title="Redundant attributes" icon="copy">
    Same information exists elsewhere in the event. Stack traces when the error code is sufficient. Full request bodies when the endpoint tells the story. Keep the log, remove the redundant attribute.
  </Accordion>
  <Accordion title="Static metadata" icon="tag">
    SDK versions, infrastructure plumbing, values that never change and never help debugging. Keep the log, remove the noise.
  </Accordion>
</AccordionGroup>

### Optimize

Some logs would be better as something else.

<AccordionGroup>
  <Accordion title="Metric-shaped logs" icon="chart-line">
    Logs created for graphing or counting. Counters, gauges, aggregations. You're paying log prices for metric data. Convert to actual metrics.
  </Accordion>
</AccordionGroup>

### Keep

Not everything is waste. A payment failure with a different user each time? 1000 customers with 1000 problems. Keep all of them. Business events, customer-specific errors, state changes like deployments. Each instance is a distinct situation worth investigating.

## Continuous evaluation

This runs continuously. Not quarterly. Not when someone remembers. Every log, evaluated against the full context of your system.

Even though Tero reasons independently about each event, every evaluation lands in a known category. Categories let you whitelist, blacklist, filter, and report. Start conservative: enable the obvious categories, review the results, expand as you build trust.

Tero discovers new patterns as we improve. Those surface as "uncategorized". Reviewed by our engineers, visible to you, a bit more experimental. This keeps you in control without restricting how the analysis evolves.

Once you understand what Tero found and why, you're ready to [take action](/questions/waste/taking-action). Review recommendations, apply policies, and track progress over time.
