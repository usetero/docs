---
title: "Malformed data"
description: "Binary blobs, corrupted output, unparseable logs"
icon: "file-circle-xmark"
iconType: "duotone"
---

Logs that aren't logs. Binary data, corrupted output, unparseable strings. They convey nothing and cost you money.

## Why it happens

Applications crash mid-write. Binary protocols get routed to text log pipelines. Encoding mismatches produce garbage. A process dumps core and the output ends up in your logs. Sometimes it's a misconfigured logger, sometimes it's a bug, sometimes it's just bad luck.

These aren't edge cases. In a large enough system, something is always emitting garbage somewhere.

## Example

<Tabs>
  <Tab title="Binary data">
    <Tabs>
      <Tab title="Before">
        ```json
        {
          "@timestamp": "2024-01-15T10:30:00Z",
          "service.name": "image-processor",
          "body": "\u0089PNG\r\n\u001a\n\u0000\u0000\u0000\rIHDR..."
        }
        ```
      </Tab>
      <Tab title="After">
        Dropped entirely.
      </Tab>
    </Tabs>

    ```yaml
    id: drop-binary-data-image-processor
    name: Drop binary data from image-processor
    description: PNG image data routed to log pipeline. Not parseable, not queryable.
    log:
      match:
        - resource_attribute: service.name
          exact: image-processor
        - log_field: body
          regex: "^\\x89PNG\\r\\n"
      keep: none
    ```
  </Tab>
  <Tab title="Truncated JSON">
    <Tabs>
      <Tab title="Before">
        ```json
        {
          "@timestamp": "2024-01-15T10:30:00Z",
          "service.name": "api-service",
          "body": "{\"user_id\": \"usr_123\", \"event\": \"login\", \"metadata\": {\"ip\":"
        }
        ```
      </Tab>
      <Tab title="After">
        Dropped entirely.
      </Tab>
    </Tabs>

    ```yaml
    id: drop-truncated-json-api-service
    name: Drop truncated JSON from api-service
    description: Incomplete JSON from buffer overflow or crash. Unparseable.
    log:
      match:
        - resource_attribute: service.name
          exact: api-service
        - log_field: body
          malformed: json
      keep: none
    ```
  </Tab>
</Tabs>

## Recommended enforcement

<Card title="Enforce at edge" icon="server" href="/policies/enforcement/edge" horizontal>
  Drop malformed logs before they reach your provider. No point paying to store garbage.
</Card>

There's no "fix at source" for most malformed data. It's usually a symptom of something breaking, not a logging decision someone made. Drop it and move on.

## How it works

Tero evaluates each log event and checks whether the content is parseable and meaningful. Binary content, truncated data, encoding errors, and garbled text are flagged as malformed.

This is objective: the log either parses or it doesn't. If it doesn't, it has no debugging value.
